---
title: Salmon Forecasts Example
author: Thomas Buehrens 
output:
  html_document:
    fig_caption: yes
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

***

This document was generated on `r format(Sys.time(), '%m/%d/%Y')`.

***


```{r set_options, echo = FALSE, message = FALSE}
options(width = 100)
knitr::opts_chunk$set(message = FALSE)
set.seed(123)
```
# Purpose
This script fits log-normal Generalized Additive Models and ARIMA models to salmon run-size data with or without regression covariates. These models are then used to generate one-year-ahead forecasts. The data used to fit the models is split into "training" and "validation" sets to evaluate performance of the one-year-ahead forecasts, compare models, and develop weighted "ensemble" forecasts.

# Requirements
All analyses require R software [**(link)**](https://cran.r-project.org/) (v3.4.3) for data retrieval, data processing, and summarizing model results.  

# Functions
We also need a couple of helper functions which we will load from the functions folder, which we will load using the walk() function from the purrr package (which we will install if it is not already installed).
```{r load_funcs, message = FALSE, warning = FALSE,results = "hide"}
#function to install or load packages
install_or_load_pack <- function(pack){
  create.pkg <- pack[!(pack %in% installed.packages()[, "Package"])]
  if (length(create.pkg))
    install.packages(create.pkg, dependencies = TRUE)
  sapply(pack, require, character.only = TRUE)
}

#fit model function for ARIMA models
fc <- function(y, h, xreg, order){
  if(!is.null(xreg)){
    if(ncol(xreg)>1){
      X <- xreg[1:length(y),]
    }else(X<-xreg[1:length(y)])
    if(NROW(xreg) < length(y) + h)
      stop("Not enough xreg data for forecasting")
    if(ncol(xreg)>1){
      if(h==1){
        newX <- t(as.matrix(xreg[length(y)+(1:h),]))
      }else(newX <- as.matrix(xreg[length(y)+(1:h),]))
    }else(newX<-xreg[length(y)+(1:h)])
    fit <-Arima(y,order=order, xreg=X,method="ML")
    #results<-forecast(fit, xreg=newX,h=h)$mean[[1]]
    results<-data.frame(forecast(fit, xreg=newX,h=h))%>%
      rename(Estimate = Point.Forecast, L95 = Lo.95, U95 =Hi.95)%>%
      dplyr::select(Estimate, L95,U95)
  }else{
    fit <- Arima(y,order=order,method="ML")
    #results<-forecast(fit,h=h)$mean[[1]]
    results<-data.frame(forecast(fit,h=h))%>%
      rename(Estimate = Point.Forecast, L95 = Lo.95, U95 = Hi.95)%>%
      dplyr::select(Estimate, L95,U95)
  }
  return(results)
}

#fc2 fit model for gam 
fc2 <- function(y, h, xreg, order){
  if(!is.null(xreg)){
    if(ncol(xreg)>1){
      X <- xreg[1:length(y),]
    }else(X<-xreg[1:length(y)])
    if(NROW(xreg) < length(y) + h)
      stop("Not enough xreg data for forecasting")
    if(ncol(xreg)>1){
      if(h==1){
        newX <- t(as.matrix(xreg[length(y)+(1:h),]))
      }else(newX <- as.matrix(xreg[length(y)+(1:h),]))
    }else(newX<-xreg[length(y)+(1:h)])
    dat<-data.frame(y,X,c(1:length(y)))
    colnames(dat)<-c("y",colnames(xreg),"year")
    formula = as.formula(paste0("exp(y) ~ s(year, m=2) + ",paste(colnames(xreg),collapse = "+")))
    fit<-gam(formula=formula,data=dat,family="nb",link=log)
    newdat<-data.frame(newX,c(length(y)+1))
    colnames(newdat)<-c(colnames(xreg),"year")
  }else{
    dat<-data.frame(y,c(1:length(y)))
    colnames(dat)<-c("y","year")
    fit<-gam(exp(y) ~ s(year, m=1, k=round(length(y)-2)),data=dat,family="nb",link=log)
    newdat<-data.frame((length(y)+1))
    colnames(newdat)<-c("year")
  }
  results<-data.frame(predict(fit, newdata = newdat,type="link",se.fit=T))%>%
    mutate(L95 = fit - 1.96 * se.fit, U95 = fit + 1.96 * se.fit)%>%
    rename(Estimate=fit,SE=se.fit)%>%
    dplyr::select(Estimate,SE,L95,U95)
  return(results)
}

#fitting wrapper for brms
fc3<-function(TY,vars,dat,formula,prior){
  TY=TY
  trainingset<-list(NULL)
  validationset<-list(NULL)
  indexes<-TY:c(dim(dat)[1]-1)
  for(i in 1:length(indexes)){
    trainingset[[i]] <- data.frame(dat[1:indexes[i],])
    validationset[[i]] <- data.frame(dat[indexes[i]+1,])
  }
  prior=prior
  mod<- brm_multiple(
    formula = formula
    ,family = gaussian()
    ,data = trainingset
    ,chains = 4
    ,cores = 4
    ,iter = 2000
    ,warmup = 1000
    ,control=list(adapt_delta = 0.99)
    ,prior=prior
    ,combine = FALSE
  )
  preds<-data.frame(matrix(NA,nrow=dim(dat)[1],ncol=4))
  for(i in 1:length(indexes)){
    preds[indexes[i]+1,] = exp(predict(mod[[i]],newdata=validationset[[i]]))
  }
  colnames(preds)<-c("Estimate","SE","L95","U95")
  return(preds)
}

#one step ahead cross validation
tsCV2<-function(y,xreg,fc,min,h,order){
  forecast<-data.frame(matrix(NA,ncol=4,nrow=1))
  colnames(forecast)<-c("Estimate","SE","L95","U95")
  for(i in min:length(y)){
    forecast[i+1,] = fc(y=y[1:i],xreg=xreg,h=h,order=order)
  }
  results<-forecast%>%
    remove_rownames()
  return(results)
}

#get NOAA SST Buoy Data
getbuoydata<-function(buoylist,years){
  df<-data.frame(matrix(NA,ncol = 4))
  colnames(df)<-c("buoyid","year","month","meanSST")
  for(i in 1:length(bouylist)){
    for(j in 1:length(years)){
      try(
        df<-df%>%
          bind_rows(buoy(dataset = "stdmet",buoyid = buoylist[i],year=years[j])$data%>%
                     dplyr::select(sea_surface_temperature,time)%>%
                     mutate(buoyid=buoylist[i]
                            ,year = format(as.Date(time),"%Y")
                            ,month = format(as.Date(time),"%m")
                            )%>%
                     group_by(buoyid,year,month)%>%
                     summarise(meanSST = mean(sea_surface_temperature))
                   )
        ,silent = T
        )
    }
  }
  df<-df%>%filter(!is.na(buoyid))
  return(df)
}

#function to download, save, process ERSST data without FTP site configuration 
get_ersst_v5_data<-function(years,data.dir,latrange, lonrange){
  df<-data.frame(matrix(NA,ncol = 5))
  colnames(df)<-c("lat","lon","sst","year","month")
  for(i in 1:years){
    for(j in 1:12){
      tdat<-NULL
      try(
        tdat<-ersst(year = years[i], month = j),
        silent = T
      )
      if(!is.null(tdat)){
        df<-df%>%
          bind_rows(data.frame(ncdf4::ncvar_get(tdat, "sst"))%>%
                      rename_with(~ncdf4::ncvar_get(tdat, "lat"))%>%
                      mutate(lon = ncdf4::ncvar_get(tdat, "lon"))%>%
                      pivot_longer(cols=-c("lon"),names_to = "lat",values_to = "sst")%>%
                      mutate(lon = ifelse(lon > 180, -360 + lon, lon),
                             lat = as.numeric(lat)
                      )%>%
                      filter(lat > min(latrange) & lat < max(latrange) & lon > min(lonrange) & lon < max(lonrange))%>%
                      mutate(year=years[i],month=j)
                    )
      }#if
    }#months
  }#years
  df<-df%>%filter(!is.na(year))
  write.csv(df,paste(data.dir,"/ersst_v5.csv",sep=""),row.names = F)
  dat<-read_csv(paste(data.dir,"/ersst_v5.csv",sep=""))%>%
    group_by(year,month)%>%
    summarize(meanSST=mean(sst,na.rm=T))%>%
    ungroup()%>%
    group_by(month)%>%
    mutate(gmeanSST=mean(meanSST,na.rm=T),resid=scale(meanSST-gmeanSST))
  return(dat)
}

#get ERSST v5 data if you have already downloaded NC file from FTP site (faster but requires prior download of data)
get_ersst_v5_data_V2<-function(years,data.dir, ncfilename, latrange,lonrange){
  dat <- nc_open(paste(data.dir,"/",ncfilename,sep=""))
  sst<-ncdf4::ncvar_get(dat, "sst")
  lon = data.frame(lon=ncdf4::ncvar_get(dat, "lon"))%>%
    rownames_to_column()%>%
    rename(lon_index=rowname)%>%
    mutate(lon_index=as.numeric(lon_index))
  lat = data.frame(lat=ncdf4::ncvar_get(dat, "lat"))%>%
    rownames_to_column()%>%
    rename(lat_index=rowname)%>%
    mutate(lat_index=as.numeric(lat_index))
  time = data.frame(time=ncdf4::ncvar_get(dat, "time"))%>%
    rownames_to_column()%>%
    rename(time_index=rowname)%>%
    mutate(time_index=as.numeric(time_index))
  dat<-data.frame(melt(sst))%>%
    rename(lon_index=Var1,lat_index=Var2,time_index=Var3, sst = value)%>%
    left_join(lon)%>%
    left_join(lat)%>%
    left_join(time)%>%
    dplyr::select(-c(lon_index,lat_index,time_index))%>%
    mutate(lon = ifelse(lon > 180, -360 + lon, lon),
    )%>%
    filter(lat > min(latrange) & lat < max(latrange) & lon > min(lonrange) & lon < max(lonrange))%>%
    mutate(date= as.Date(time,origin="1800-01-01"))%>%
    mutate(year = format(date,"%Y")
           ,month = format(date,"%m")
           )%>%
    filter(year >= min(years) & year <= max(years))
  write.csv(dat,paste(data.dir,"/ersst_v5.csv",sep=""),row.names = F)
  dat<-read_csv(paste(data.dir,"/ersst_v5.csv",sep=""))%>%
      group_by(year,month)%>%
    summarize(meanSST=mean(sst,na.rm=T))%>%
    ungroup()%>%
    group_by(month)%>%
    mutate(gmeanSST=mean(meanSST,na.rm=T))%>%
    ungroup()%>%
    mutate(resid=meanSST-gmeanSST)
  return(dat)
}
#optimization algorithm to find best stacking weights
find_stack_weights<-function(tau,metric,n,initial_weights,preds,obs){
  tweights<-initial_weights
  preds<-as.matrix(preds)
  obs<-obs
  tau=tau
  skill_list<-c(NULL)
  metric=metric
  for(i in 1:n){
    pred_trs_ensemble<- preds %*% as.vector(tweights)
    Error <- pred_trs_ensemble - obs
    SE <- Error^2
    PE <- Error/obs
    APE <- abs(PE)
    LAR <- log(obs/pred_trs_ensemble)
  
    RMSE <- apply(SE,2,function(x){sqrt(mean(x))})
    MPE <- apply(PE,2,function(x){mean(x)})
    MAPE <- apply(APE,2,function(x){mean(x)})
    MSA <- apply(LAR,2,function(x){100*(exp(mean(abs(x)))-1)})
    
    if(i==1){
      skill=get(metric)
      weights=tweights
    }
    if(get(metric)<skill){
      skill=get(metric)
      weights=tweights
    }
    skill_list<-c(skill_list,min(get(metric),skill))
    keep<-rbinom(1,prob=skill/get(metric),1)
    if(keep==1){tweights=tweights }else(tweights=weights)
    tweights = rdirichlet(n=1,alpha = tweights*tau+0.001)
  }
  results<-list(weights,skill,skill_list)
  return(results)
}
```

# Packages
Here we will load & install packages we need to use (needs internet connection if packages not already installed)
```{r load_packages, message = FALSE, warning = FALSE,results = "hide"}
packages_list<-c("tidyverse"
                 ,"forecast"
                 ,"mgcv"
                 ,"ggplot2"
                 ,"MASS"
                 ,"RColorBrewer"
                 ,"kableExtra"
                 ,"gtools"
                 # ,"ggfortify"
                 # ,"brms"
                 # ,"rnoaa"
                 # ,"ncdf4"
                 # ,"ncdf4.helpers"
                 # ,"raster"
                 # ,"reshape2"
                 # ,"ggfortify"
                 )
install_or_load_pack(pack = packages_list)
```

# Fish Data
Here we will load and format our data for analysis. What you load is what you will forecast (so you can forecast run size or escapement)
```{r load_data, message = FALSE, warning = FALSE,results = "show"}
#====================================
#get columbia Chinook data as example
#====================================
dat<-read_csv("http://www.cbr.washington.edu/dart/cs/php/rpt/adult_annual.php?sc=1&outputFormat=csv&proj=BON&startdate=1%2F1&enddate=6%2F15")%>%
  arrange(Year)%>%
  filter(`Jack Chinook`!=0)%>%
  dplyr::select(Year, Chinook, `Jack Chinook`)%>%
  mutate(`Chinook`=ifelse(as.numeric(Year)<as.numeric(format(Sys.Date(),"%Y")),`Chinook`,NA),`Jack Chinook`=ifelse(as.numeric(Year)<as.numeric(format(Sys.Date(),"%Y")),`Jack Chinook`,NA))%>%
  mutate(lag1_logJCK=lag(scale(log(`Jack Chinook`))))%>%
  filter(!is.na(lag1_logJCK))

#look at our data  
print(head(data.frame(dat)))
```

# Get Covariate Data (optional)
Code below will download NOAA Ocean Indicator data, NOAA Ocean Buoy SST data, and NOAA smoothed modelled SST data (ERSST_V5)
```{r get_covariate_data, message = FALSE, warning = FALSE,results = "hide"}
#=========================================================
#get NOAA indicator data, wrangle into usable format, plot
#=========================================================
NPGO<-read_table("http://www.o3d.org/npgo/npgo.php",skip=29,col_names=F,comment="#")%>%
  filter(!is.na(X2))%>%
  dplyr::rename(year=X1,Month=X2,NPGO=X3)%>%
  mutate(year=as.numeric(year))%>%
  group_by(year)%>%
  add_tally()%>%
  filter(!Month>6)%>% #use only spring (Jan-June) NPGO
  #filter(!n < 12)%>% #use only complete years
  group_by(year)%>%
  dplyr::summarise(mean_NPGO=mean(NPGO))
#=========================================================
#get NOAA indicator data, wrangle into usable format, plot
#=========================================================
# indicators<-read_csv("https://media.fisheries.noaa.gov/2021-04/Stoplight%20csv.csv?null",skip=1)%>%
#   filter(!is.na(`Ecosystem Indicators`))%>%
#   pivot_longer(names_to = "Year",
#                 cols=c(starts_with("1"),starts_with("2")),
#                 values_to = "value")%>%
#   pivot_wider(names_from=`Ecosystem Indicators`,values_from=value)%>%
#   mutate(Year=as.numeric(Year))
# 
# plotdat<-indicators%>%pivot_longer(names_to = "indicators", cols = colnames(indicators)[colnames(indicators)!="Year"])
# ggplot(plotdat,aes(x=value,color=indicators))+
#   geom_density()+
#   facet_wrap(~indicators,scales="free")+
#   theme(legend.position = "none")

#==============================================================
# get NOAA sst data directly from Buoys (takes a while to run)
#==============================================================
# buoylist<-c(46229, 46211, 46041, 46029, 46050, 46097, 46098)
# years<-c(1980:2021)
# buoy_stations()%>%filter(lat > 44 & lat < 52 & lon > -130 & lon < -120)
# buoydat<-getbuoydata(buoylist = buoylist,years=years)
# write.csv(dat,"SST.csv",row.names = F)

#===================
#Plot Buoy SST data
#====================
# buoydat<-buoydat%>%
#   filter(!is.na(buoyid) & !is.na(meanSST))%>%
#   group_by(buoyid,month)%>%
#   mutate(gmeanSST=mean(meanSST),resid=meanSST-gmeanSST)
#   
# 
# ggplot(buoydat,aes(x=month,y=resid,group=factor(buoyid),color=factor(buoyid)))+
#   geom_hline(yintercept=0,linetype="dashed")+
#   scale_color_brewer(palette = "Spectral")+
#   geom_line()+
# facet_wrap(~factor(year))


#===========================================================================================================
#Get ERSST data: get_ersst_v5_data takes A LONG TIME (1 hr) vs. get_ersst_v5_data_V2 which is much quicker!
#===========================================================================================================
#dat<-get_ersst_v5_data(years=years,data.dir=getwd(),latrange=c(44,52),lonrange=c(-130,-120))
# data.dir<-"C:/Users/buehrtwb/OneDrive - Washington State Executive Branch Agencies/Documents"
# sstdat<-get_ersst_v5_data_V2(years=c(1980:2021),data.dir=data.dir ,ncfilename="SSTv5.nc",latrange=c(44,50),lonrange=c(-125,-120))
# 
# sstdat<-sstdat%>%
#   mutate(sstdiff=c(NA,diff(resid)))
# 
# #================
# #Plot ERSST data
# #================
# ggplot(sstdat,aes(x=factor(month),y=meanSST,group=year))+
#   geom_hline(yintercept=0,linetype="dashed")+
#   scale_color_brewer(palette = "Spectral")+
#   geom_line()+
#   facet_wrap(~factor(year))
# 
# ggplot(sstdat,aes(x=factor(month),y=resid,group=year))+
#   geom_hline(yintercept=0,linetype="dashed")+
#   scale_color_brewer(palette = "Spectral")+
#   geom_line()+
#   facet_wrap(~factor(year))
# 
# ggplot(sstdat,aes(x=factor(month),y=sstdiff,group=year))+
#   geom_hline(yintercept=0,linetype="dashed")+
#   scale_color_brewer(palette = "Spectral")+
#   geom_line()+
#   facet_wrap(~factor(year))
# 
# ssta<-sstdat%>%
#   dplyr::select(year,month,resid)%>%
#   mutate(month = paste0("m_",month))%>%
#   rename(Year = year)%>%
#   pivot_wider(names_from = month,values_from = resid)
# 
# pcdat<-ssta%>%
#   ungroup()%>%
#   filter(Year<2021)%>%
#   column_to_rownames(var="Year")
# mod<-prcomp(pcdat
#             )
# autoplot(mod,data=ssta%>%filter(Year<2021)%>%column_to_rownames(var="Year"),
#          x=1,
#          y=3,
#          label = TRUE, 
#          label.size = 3,
#          shape=F)
```

# Merge Covariate Data (optional)
If we loaded/downloaded covariate data (other than fish abundance) for use in forecasting, we can merge it with our fish data here
```{r merge_covariate_data, message = FALSE, warning = FALSE,results = "hide"}
#dat<-dat%>%
  #left_join(NPGO)%>%
  #left_join(indicators)%>%
  #left_join(ssta)%>%
  #mutate(
    # l1aprssta= lag(scale(m_04)),
    # l1mayssta= lag(scale(m_05)),
    # l1junssta= lag(scale(m_06)),
    # l1julssta= lag(scale(m_07)),
    # l1augssta= lag(scale(m_08)),
    # l1sepssta= lag(scale(m_09)),
    # l1octssta= lag(scale(m_10)),
    # l1novssta= lag(scale(m_11)),
    # l1decssta= lag(scale(m_12)),
    # l1FallSST= (lag(scale(m_10)) + lag(scale(m_11)) + lag(scale(m_12)))/3
    # PC1 = lag(mod$x[,1]),
    # PC2 = lag(mod$x[,2]),
    # PC3 = lag(mod$x[,3]),
    # lag1_summerPDO = lag(scale(`PDO\n(Sum May-Sept)`)),
    # lag1_springONI = lag(scale(`ONI\n(Average Jan-June)`)),
    # lag1_summerdeepSST = lag(scale(`Deep temperature\n(°C; May-Sept)`)),
    # lag1_summerdeepSalinity = lag(scale(`Deep salinity\n(May-Sept)`)),
    # lag1_copepodrich = lag(scale(`Deep salinity\n(May-Sept)`)),
    # lag1_icthy = lag(scale(`Nearshore Ichthyoplankton\nLog(mg C 1,000 m-3; Jan-Mar)`)),
    # lag1_cpueCO = lag(scale(log(`Coho salmon juvenile\ncatches (no. km-1; June)`))),
    # lag1_phystrans = lag (scale(`Physical Spring Trans.\nUI based (day of year)`)),
    # lag1_Ncope = lag(scale(`N. copepod biomass anom.\n(mg C m-3; May-Sept)`)),
    # lag1_summerSST=lag(scale(`Upper 20 m T\n(°C; May-Sept)`)),
    # lag1_PC1 = scale(lag(`Principal Component scores (PC1)`)),
    # lag1_PC2 = lag(`Principal Component scores (PC2)`),
    #)#%>%filter(!is.na(lag1_summerSST))
#look at our data  
#print(data.frame(dat))  
```

# Set Parameters
Here we specify parameters: how many years of training data to include in the training set (validation is the rest), how many years forward to forecast (typically 1), which regression covariates to include
```{r set_parameters, message = FALSE, warning = FALSE,results = "hide"}
TY <- dim(dat)[1]-21 #training years (years of training data)
FY <- 1 #forecast years (years foreward to forecast)
vars<-c("lag1_logJCK") #what regression variables will we use?
dat<-data.frame(dat)%>%dplyr::select(Year,Chinook,all_of(vars))
#for gam fits and r-arima fits
xreg=as.matrix(dat%>%dplyr::select(lag1_logJCK))
k = 1 #this is the model-averaging weighting exponent--default is 1, larger numbers will tend to more heavily weight "best" models over lower ranked models
stack_metric = "MSA" #this is the performance measure that will be optimized to find the best stack weights
```

# Fit Forecast Models
Here we will fit ARIMA and GAM forecast
```{r fit_forecasts, message = FALSE, warning = FALSE,results = "hide"}
#==========
#ARIMA models
#==========
LFO1<-tsCV2(y=log(dat$Chinook[-dim(dat)[1]]),
              xreg=NULL,
              h=FY,
              min=TY,
              fc=fc,
              order=c(1,0,0)
)
LFO2<-tsCV2(y=log(dat$Chinook[-dim(dat)[1]]),
      xreg=xreg,
      h=FY,
      min=TY,
      fc=fc,
      order=c(1,0,0)
      )

LFO3<-tsCV2(y=log(dat$Chinook[-dim(dat)[1]]),
            xreg=xreg,
            h=FY,
            min=TY,
            fc=fc,
            order=c(1,1,1)
)
LFO4<-tsCV2(y=log(dat$Chinook[-dim(dat)[1]]),
            xreg=xreg,
            h=FY,
            min=TY,
            fc=fc,
            order=c(0,1,0)
)
LFO5<-tsCV2(y=log(dat$Chinook[-dim(dat)[1]]),
            xreg=NULL,
            h=FY,
            min=TY,
            fc=fc,
            order=c(0,1,0)
)
# LFO6<-tsCV2(y=log(dat$Chinook[-dim(dat)[1]]),
#             xreg=NULL,
#             h=FY,
#             min=TY,
#             fc=fc,
#             order=c(1,1,1)
# )
LFO7<-tsCV2(y=log(dat$Chinook[-dim(dat)[1]]),
            xreg=xreg,
            h=FY,
            min=TY,
            fc=fc,
            order=c(1,0,1)
)
LFO8<-tsCV2(y=log(dat$Chinook[-dim(dat)[1]]),
            xreg=NULL,
            h=FY,
            min=TY,
            fc=fc,
            order=c(1,0,1)
)
#==========
#GAM models
#==========
LFO9<-tsCV2(y=log(dat$Chinook[-dim(dat)[1]]),
            xreg=NULL,
            h=FY,
            min=TY,
            fc=fc2,
            order=c(NA,NA,NA)
)
LFO10<-tsCV2(y=log(dat$Chinook[-dim(dat)[1]]),
            xreg=xreg,
            h=FY,
            min=TY,
            fc=fc2,
            order=c(NA,NA,NA)
)
#================================
#BRMS models with Horseshoe Prior
#================================
# LFO11<-fc3(
#   TY=TY
#   ,vars=vars
#   ,dat=dat
#   ,formula = as.formula(paste0("log(Coho) ~ gp(Year) + ",paste(vars,collapse = "+")))
#   ,prior = set_prior(horseshoe(df = 1, par_ratio = 0.5), class="b")
# )

# LFO12<-fc3(
#   TY=TY
#   ,vars=vars
#   ,dat=dat
#   ,formula = as.formula(paste0("log(Coho) ~ arma(p = 1, q = 1, cov=TRUE) + ",paste(vars,collapse = "+")))
#   ,prior = set_prior(horseshoe(df = 1, par_ratio = 0.5), class="b")
# )
```

# Summarize Forecasts 
Here we will summarize our forecasts for the last year of our covariate data and we will plot our observed and forecasted runsize for all models
```{r summarize_forecasts, message = FALSE, warning = FALSE, results = "asis", include=TRUE}
#===================
#Summarize Forecasts
#===================
dat2<-bind_cols(Year=dat$Year,
    ARIMA100=exp(LFO1$Estimate),
    ARIMA100_withcov=exp(LFO2$Estimate),
    ARIMA111_withcov=exp(LFO3$Estimate),
    #ARIMA111=exp(LFO6$Estimate),
    ARIMA010_withcov=exp(LFO4$Estimate),
    ARIMA010=exp(LFO5$Estimate),
    ARIMA101_withcov=exp(LFO7$Estimate),
    ARIMA101=exp(LFO8$Estimate),
    gam=exp(LFO9$Estimate),
    gam_withcov=exp(LFO10$Estimate),
    #gp_horseshoe = LFO11$Estimate,
    #ARIMA101_horseshoe = LFO12$Estimate
            )%>%
    pivot_longer(names_to = "Model",
               cols=c(starts_with("ARIMA"),starts_with("gam"),starts_with("gp")),
               values_to = "Chinook")

dat2%>%filter(Year==max(Year))%>%
  kbl(caption = "Table 1. Forecasts for final year of data.",digits =0)%>%
  kable_classic(full_width = F, html_font = "Cambria")

#===========================
#Plot of final year forecast
#===========================
ggplot(data=dat2,aes(x=Year,y=Chinook,color=Model))+
  labs(title="One-Year-Ahead Forecasts")+
  geom_line(size=1)+
  scale_color_brewer(palette="Spectral")+
  geom_point(data=dat%>%mutate(Model="Observed"),mapping=aes(x=Year,y=Chinook),size=2,color="black")+
  theme_bw()
```

# Evaluate Forecasts
Here we will evaluate forecasts using Mean Absolute Percent Error (MAPE), Root Mean Squared Error (RMSE), and Median Symmetric Accuracy (MSA). RMSE and MAPE tend to more heavily penalize over-forecasts relative to under-forecasts for abundance (because errors are right-skewed), whereas MSA is specifically tailored for right tailed distributions. We will also calculated model weights
```{r evaluate_forecasts, message = FALSE, warning = FALSE,results = "show"}
dat3<-dat2%>%
  left_join(dat,by="Year")%>%
  dplyr::select(Year,Model,Chinook.x,Chinook.y)%>%
  mutate(error=Chinook.y-Chinook.x)%>%
  filter(!is.na(error))%>%
  group_by(Model)%>%
  summarise(RMSE = sqrt(mean(error^2)),
            MAPE = mean(abs(error/Chinook.y))*100,
            MSA = 100*(exp(mean(abs(log(Chinook.y/Chinook.x))))-1)
              )%>%
  arrange(MSA)

dat3%>%
  kbl(caption = "Table 2.Forecast Performance based on full set of one-year-ahead forecasts.",digits =3)%>%
  kable_classic(full_width = F, html_font = "Cambria")
```


# Ensembles & Ensemble Performance
Calculate leave-forward-out performance year by year in order to develop weighted ensembles (with recalculated weights each year). Then evaluate performance of these one-year-ahead ensembles.
````{r develop and evaluate ensembles, message = FALSE, warning = FALSE,results = "show"}
yrrange<-dat2%>%
  filter(!is.na(Chinook))%>%
  summarise(minyr=min(Year),maxyr=max(Year))%>%
  unlist()

ensembles<-NULL
for(i in 2: length(yrrange[1]:yrrange[2])){
  years<-c(yrrange[1]:(yrrange[1]+i-1))
  tdat<-dat2%>%
  filter(Year %in% years)%>%
  left_join(dat,by="Year")%>%
  dplyr::select(Year,Model,Chinook.x,Chinook.y)%>%
  mutate(error=Chinook.y-Chinook.x)%>%
  filter(!is.na(error))%>%
  group_by(Model)%>%
  summarise(RMSE = sqrt(mean(error^2)),
            MAPE = mean(abs(error/Chinook.y))*100,
            MSA = 100*(exp(mean(abs(log(Chinook.y/Chinook.x))))-1)
              )%>%
  arrange(MSA)%>%
  mutate(MSA_weight=(1/MSA)^k/sum((1/MSA)^k), 
         RMSE_weight =(1/RMSE)^k/sum((1/RMSE)^k),
         MAPE_weight =(1/MAPE)^k/sum((1/MAPE)^k)
  )

  modelcnt<-length(unique(dat2$Model))
  stackyears<-years[years!=max(years)]
  stackdat<-dat2%>%
    filter(Year %in% years)%>%
    filter(!is.na(Chinook))%>%
    pivot_wider(names_from = Model, values_from = Chinook,id_cols = Year)%>%
    left_join(dat%>%dplyr::select(Year,Chinook))

  stack_weights<-find_stack_weights(tau=1,
                     n=10000,
                     metric=stack_metric,
                     initial_weights=rep(1/modelcnt,modelcnt),
                     preds=stackdat%>%
                       filter(!is.na(Chinook))%>%
                       dplyr::select(!Chinook & !Year)%>%
                       as.matrix(),
                     obs=stackdat%>%
                       filter(!is.na(Chinook))%>%
                       dplyr::select(Chinook & !Year)%>%
                       as.matrix()
                     )
  stacking_weights<-data.frame("Stacking_weight" = as.vector(round(unlist(stack_weights[[1]]),4)))
  stacking_weights$Model<-colnames(stackdat)[!colnames(stackdat)%in%c("Year","Chinook")]
  tdat<-tdat%>%
    left_join(stacking_weights)
  
  
  
  tdat2<-dat2%>%
    filter(Year == max(years))%>%
    left_join(tdat)%>%
    mutate(MSA_weighted = Chinook * MSA_weight,
           RMSE_weighted = Chinook * RMSE_weight,
           MAPE_weighted = Chinook * MAPE_weight,
           Stack_weighted = Chinook * Stacking_weight,
           )%>%
    group_by(Year)%>%
    summarise(MSA_weighted = sum(MSA_weighted),
              RMSE_weighted = sum(RMSE_weighted),
              MAPE_weighted = sum(MAPE_weighted),
              Stack_weighted = sum(Stack_weighted),
              )%>%
    pivot_longer(names_to = "Model",
                 cols=c("MSA_weighted","RMSE_weighted","MAPE_weighted","Stack_weighted"),
                 values_to = "Chinook")
  
  ensembles<-bind_rows(ensembles,tdat2)

}

#=================================
#Table of final year model weights
#=================================
tdat%>%
  dplyr::select(Model, RMSE_weight, MAPE_weight, MSA_weight, Stacking_weight)%>%
  kbl(caption = "Table 3. Final Year Model Weights based on full dataset of one-year-ahead performance.",digits =3)%>%
  kable_classic(full_width = F, html_font = "Cambria")

#=======================================
#Table of final year ensemable forecasts
#=======================================
ensembles%>%
  filter(Year==max(Year))%>%
  kbl(caption = "Table 4. Ensemble forecasts one year ahead of final year of data.",digits =0)%>%
  kable_classic(full_width = F, html_font = "Cambria")

#=============================
#calc performance of ensembles
#=============================
dat4<-bind_rows(dat2,ensembles)%>%
  filter(Year>min(yrrange))%>%
  left_join(dat,by="Year")%>%
  dplyr::select(Year,Model,Chinook.x,Chinook.y)%>%
  mutate(error=Chinook.y-Chinook.x)%>%
  filter(!is.na(error))%>%
  #dplyr::select(Year,Model,error)%>%
  group_by(Model)%>%
  summarise(RMSE = sqrt(mean(error^2)),
            MAPE = mean(abs(error/Chinook.y))*100,
            MSA = 100*(exp(mean(abs(log(Chinook.y/Chinook.x))))-1)
  )%>%
  arrange(MSA)

dat4%>%
  kbl(caption = "Table 5. One-year ahead performance of model & model ensemble forecasts. Ensemble weights recalculated annually using weights based on one-head performance up to to and including the year prior to the forecast year. Year one of one-year ahead fits not included since an ensemble cannot be computed for this year.",digits =3)%>%
  kable_classic(full_width = F, html_font = "Cambria")

#==============
#plot ensemble forecasts
#==============
ggplot(data=ensembles,aes(x=Year,y=Chinook,color=Model))+
  labs(title="One-Year-Ahead Ensemble Forecasts")+
  geom_line(size=1)+
  scale_color_brewer(palette="Spectral")+
  geom_point(data=dat%>%mutate(Model="Observed"),mapping=aes(x=Year,y=Chinook),size=2,color="black")+
  theme_bw()

```

